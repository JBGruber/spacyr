<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Using spacyr • spacyr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/readable/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Using spacyr">
<meta property="og:description" content="spacyr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">spacyr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.3.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Installation</a>
</li>
<li>
  <a href="../articles/using_spacyr.html">Using spacyr</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/quanteda/spacyr" class="external-link">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Using spacyr</h1>
                        <h4 data-toc-skip class="author">Kenneth Benoit
and Akitaka Matsuo</h4>
            
            <h4 data-toc-skip class="date">2023-12-06</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/quanteda/spacyr/blob/HEAD/vignettes/using_spacyr.Rmd" class="external-link"><code>vignettes/using_spacyr.Rmd</code></a></small>
      <div class="hidden name"><code>using_spacyr.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><strong>spacyr</strong> provides a convenient R wrapper around the
Python <a href="https://spacy.io" class="external-link">spaCy</a> package. It offers easy
access to the following functionality of spaCy:</p>
<ul>
<li>parsing texts into tokens or sentences;</li>
<li>lemmatizing tokens;</li>
<li>parsing dependencies (to identify the grammatical structure of the
sentence); and</li>
<li>identifying, extracting, or consolidating token sequences that form
named entities or noun phrases.</li>
</ul>
<p>It also allows a user to request additional token-level attributes
directly from spaCy.</p>
<p><strong>spacyr</strong> also takes care of the installation of not
only spaCy but also Python itself, in a self-contained miniconda or
virtualenv environment, and can install additional language models or
upgrade spaCy as new models and versions become available.</p>
<p>Finally, <strong>spacyr</strong> works seamlessly with the <a href="https://quanteda.io" class="external-link"><strong>quanteda</strong></a> package,
although such use is optional.</p>
</div>
<div class="section level2">
<h2 id="starting-a-spacyr-session">Starting a <strong>spacyr</strong> session<a class="anchor" aria-label="anchor" href="#starting-a-spacyr-session"></a>
</h2>
<p><strong>spacyr</strong> works through the <a href="https://github.com/rstudio/reticulate" class="external-link"><strong>reticulate</strong></a>
package that allows R to harness the power of Python. To access the
underlying Python functionality, <strong>spacyr</strong> must open a
connection by being initialized within your R session.</p>
<p>We provide a function for this, <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code>,
which attempts to make this process as painless as possible. When spaCy
has been installed in a conda environment with
<code><a href="../reference/spacy_install.html">spacy_install()</a></code> (and see <a href="https://spacyr.quanteda.io" class="external-link uri">https://spacyr.quanteda.io</a> for detailed instructions on
this setup), <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code> automatically detects it
and initializes spaCy. If spaCy is installed in a normal environment
(i.e. not in a condaenv or virtualenv), <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code>
searches your system for Python executables, and testing which have
spaCy installed.</p>
<p>For power users with a specialized setup of spaCy (i.e. users who
have a conda environment already set up for spaCy), it is possible to
specify which environment or python executable to be used through one of
the following methods:</p>
<ol style="list-style-type: decimal">
<li>
<code>condaenv</code> argument: supplying the name of conda
environment</li>
<li>
<code>virtualenv</code> argument: supplying the path to the python
virtual environment</li>
<li>
<code>python_executable</code> argument: supplying the path to the
python</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://spacyr.quanteda.io" class="external-link">"spacyr"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/spacy_initialize.html">spacy_initialize</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"en_core_web_sm"</span><span class="op">)</span></span>
<span><span class="co">## successfully initialized (spaCy Version: 3.7.2, language model: en_core_web_sm)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="tokenizing-and-tagging-texts">Tokenizing and tagging texts<a class="anchor" aria-label="anchor" href="#tokenizing-and-tagging-texts"></a>
</h2>
<p>The <code><a href="../reference/spacy_parse.html">spacy_parse()</a></code> function is <strong>spacyr</strong>’s
main workhorse. It calls spaCy both to tokenize and tag the texts. It
provides two options for part of speech tagging, plus options to return
word lemmas, recognize names entities or noun phrases recognition, and
identify grammatical structures features by parsing syntactic
dependencies. It returns a <code>data.frame</code> corresponding to the
emerging <a href="https://github.com/ropenscilabs/tif" class="external-link"><em>text
interchange format</em></a> for token data.frames.</p>
<p>The tokenization approach taken by spaCy is inclusive: it includes
all tokens without restrictions, including punctuation characters and
symbols.</p>
<p>Example:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">txt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>d1 <span class="op">=</span> <span class="st">"spaCy is great at fast natural language processing."</span>,</span>
<span>         d2 <span class="op">=</span> <span class="st">"Mr. Smith spent two years in North Carolina."</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># process documents and obtain a data.table</span></span>
<span><span class="va">parsedtxt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span><span class="op">)</span></span>
<span><span class="va">parsedtxt</span></span>
<span><span class="co">##    doc_id sentence_id token_id      token      lemma   pos   entity</span></span>
<span><span class="co">## 1      d1           1        1      spaCy      spacy  INTJ         </span></span>
<span><span class="co">## 2      d1           1        2         is         be   AUX         </span></span>
<span><span class="co">## 3      d1           1        3      great      great   ADJ         </span></span>
<span><span class="co">## 4      d1           1        4         at         at   ADP         </span></span>
<span><span class="co">## 5      d1           1        5       fast       fast   ADJ         </span></span>
<span><span class="co">## 6      d1           1        6    natural    natural   ADJ         </span></span>
<span><span class="co">## 7      d1           1        7   language   language  NOUN         </span></span>
<span><span class="co">## 8      d1           1        8 processing processing  NOUN         </span></span>
<span><span class="co">## 9      d1           1        9          .          . PUNCT         </span></span>
<span><span class="co">## 10     d2           1        1        Mr.        Mr. PROPN         </span></span>
<span><span class="co">## 11     d2           1        2      Smith      Smith PROPN PERSON_B</span></span>
<span><span class="co">## 12     d2           1        3      spent      spend  VERB         </span></span>
<span><span class="co">## 13     d2           1        4        two        two   NUM   DATE_B</span></span>
<span><span class="co">## 14     d2           1        5      years       year  NOUN   DATE_I</span></span>
<span><span class="co">## 15     d2           1        6         in         in   ADP         </span></span>
<span><span class="co">## 16     d2           1        7      North      North PROPN    GPE_B</span></span>
<span><span class="co">## 17     d2           1        8   Carolina   Carolina PROPN    GPE_I</span></span>
<span><span class="co">## 18     d2           1        9          .          . PUNCT</span></span></code></pre></div>
<p>Two fields are available for part-of-speech tags. The
<code>pos</code> field returned is the <a href="https://universaldependencies.org/u/pos/all.html" class="external-link">Universal tagset
for parts-of-speech</a>, a general scheme that most users will find
serves their needs, and also that provides equivalencies across
languages. <strong>spacyr</strong> also provides a more detailed tagset,
defined in each spaCy language model. For English, this is the <a href="https://spacy.io/docs/usage/pos-tagging#pos-tagging-english" class="external-link">OntoNotes
5 version of the Penn Treebank tag set</a>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span>, tag <span class="op">=</span> <span class="cn">TRUE</span>, entity <span class="op">=</span> <span class="cn">FALSE</span>, lemma <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">##    doc_id sentence_id token_id      token   pos tag</span></span>
<span><span class="co">## 1      d1           1        1      spaCy  INTJ  UH</span></span>
<span><span class="co">## 2      d1           1        2         is   AUX VBZ</span></span>
<span><span class="co">## 3      d1           1        3      great   ADJ  JJ</span></span>
<span><span class="co">## 4      d1           1        4         at   ADP  IN</span></span>
<span><span class="co">## 5      d1           1        5       fast   ADJ  JJ</span></span>
<span><span class="co">## 6      d1           1        6    natural   ADJ  JJ</span></span>
<span><span class="co">## 7      d1           1        7   language  NOUN  NN</span></span>
<span><span class="co">## 8      d1           1        8 processing  NOUN  NN</span></span>
<span><span class="co">## 9      d1           1        9          . PUNCT   .</span></span>
<span><span class="co">## 10     d2           1        1        Mr. PROPN NNP</span></span>
<span><span class="co">## 11     d2           1        2      Smith PROPN NNP</span></span>
<span><span class="co">## 12     d2           1        3      spent  VERB VBD</span></span>
<span><span class="co">## 13     d2           1        4        two   NUM  CD</span></span>
<span><span class="co">## 14     d2           1        5      years  NOUN NNS</span></span>
<span><span class="co">## 15     d2           1        6         in   ADP  IN</span></span>
<span><span class="co">## 16     d2           1        7      North PROPN NNP</span></span>
<span><span class="co">## 17     d2           1        8   Carolina PROPN NNP</span></span>
<span><span class="co">## 18     d2           1        9          . PUNCT   .</span></span></code></pre></div>
<p>The Penn Treebank is specific to English parts of speech. For other
language models, the detailed tagset will be based on a different
scheme. In the German language model, for instance, the universal tagset
(<code>pos</code>) remains the same, but the detailed tagset
(<code>tag</code>) is based on the <a href="https://spacy.io/docs/usage/pos-tagging#pos-tagging-german" class="external-link">TIGER
Treebank</a> scheme. Full details are available from the <a href="https://spacy.io/models/" class="external-link">spaCy models web page</a>.</p>
<p>Direct parsing of texts is also possible, using
<strong>spacy_tokenize()</strong>. The options are designed to match
those in the <a href="https://quanteda.io/reference/tokens.html" class="external-link"><code>tokens()</code>
function</a> from the <strong>quanteda</strong> package. By default this
returns a named list (where the document name is the list element
name):</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_tokenize.html">spacy_tokenize</a></span><span class="op">(</span><span class="va">txt</span><span class="op">)</span></span>
<span><span class="co">## $d1</span></span>
<span><span class="co">## [1] "spaCy"      "is"         "great"      "at"         "fast"      </span></span>
<span><span class="co">## [6] "natural"    "language"   "processing" "."         </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $d2</span></span>
<span><span class="co">## [1] "Mr."      "Smith"    "spent"    "two"      "years"    "in"       "North"   </span></span>
<span><span class="co">## [8] "Carolina" "."</span></span></code></pre></div>
<p>but it can also output a data.frame:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_tokenize.html">spacy_tokenize</a></span><span class="op">(</span><span class="va">txt</span>, remove_punct <span class="op">=</span> <span class="cn">TRUE</span>, output <span class="op">=</span> <span class="st">"data.frame"</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">##    doc_id    token</span></span>
<span><span class="co">## 11     d2    spent</span></span>
<span><span class="co">## 12     d2      two</span></span>
<span><span class="co">## 13     d2    years</span></span>
<span><span class="co">## 14     d2       in</span></span>
<span><span class="co">## 15     d2    North</span></span>
<span><span class="co">## 16     d2 Carolina</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="extracting-language-properties-from-texts">Extracting language properties from texts<a class="anchor" aria-label="anchor" href="#extracting-language-properties-from-texts"></a>
</h2>
<div class="section level3">
<h3 id="entity-and-noun-phrase-recognition">Entity and noun phrase recognition<a class="anchor" aria-label="anchor" href="#entity-and-noun-phrase-recognition"></a>
</h3>
<p><strong>spacyr</strong> can extract entities, either named or <a href="https://spacy.io/api/annotation#named-entities" class="external-link">“extended”</a>
from the output of <code><a href="../reference/spacy_parse.html">spacy_parse()</a></code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">parsedtxt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span>, lemma <span class="op">=</span> <span class="cn">FALSE</span>, entity <span class="op">=</span> <span class="cn">TRUE</span>, nounphrase <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/entity_extract.html">entity_extract</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">##   doc_id sentence_id         entity entity_type</span></span>
<span><span class="co">## 1     d2           1          Smith      PERSON</span></span>
<span><span class="co">## 2     d2           1 North_Carolina         GPE</span></span></code></pre></div>
<p>“Extended” entities including entities such as dates, events, and
cardinal or ordinal quantities.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/entity_extract.html">entity_extract</a></span><span class="op">(</span><span class="va">parsedtxt</span>, type <span class="op">=</span> <span class="st">"all"</span><span class="op">)</span></span>
<span><span class="co">##   doc_id sentence_id         entity entity_type</span></span>
<span><span class="co">## 1     d2           1          Smith      PERSON</span></span>
<span><span class="co">## 2     d2           1      two_years        DATE</span></span>
<span><span class="co">## 3     d2           1 North_Carolina         GPE</span></span></code></pre></div>
<p>One very useful feature is to use the consolidation functions to
compound multi-word entities into single “tokens” (as they would in a
language like German):</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/entity_extract.html">entity_consolidate</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">##    doc_id sentence_id token_id          token    pos entity_type</span></span>
<span><span class="co">## 11     d2           1        2          Smith ENTITY      PERSON</span></span>
<span><span class="co">## 12     d2           1        3          spent   VERB            </span></span>
<span><span class="co">## 13     d2           1        4      two_years ENTITY        DATE</span></span>
<span><span class="co">## 14     d2           1        5             in    ADP            </span></span>
<span><span class="co">## 15     d2           1        6 North_Carolina ENTITY         GPE</span></span>
<span><span class="co">## 16     d2           1        7              .  PUNCT</span></span></code></pre></div>
<p>In a similar manner to named entity extraction,
<strong>spacyr</strong> can extract or concatenate [noun phrases* (or <a href="https://spacy.io/usage/linguistic-features#noun-chunks" class="external-link"><em>noun
chunks</em></a>).</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/nounphrase_extract.html">nounphrase_extract</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">##   doc_id sentence_id                       nounphrase</span></span>
<span><span class="co">## 1     d1           1 fast_natural_language_processing</span></span>
<span><span class="co">## 2     d2           1                        Mr._Smith</span></span>
<span><span class="co">## 3     d2           1                        two_years</span></span>
<span><span class="co">## 4     d2           1                   North_Carolina</span></span></code></pre></div>
<p>Just as with entities, noun phrases can also be consolidated into
single “tokens”:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/nounphrase_extract.html">nounphrase_consolidate</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">##    doc_id sentence_id token_id                            token        pos</span></span>
<span><span class="co">## 1      d1           1        1                            spaCy       INTJ</span></span>
<span><span class="co">## 2      d1           1        2                               is        AUX</span></span>
<span><span class="co">## 3      d1           1        3                            great        ADJ</span></span>
<span><span class="co">## 4      d1           1        4                               at        ADP</span></span>
<span><span class="co">## 5      d1           1        5 fast_natural_language_processing nounphrase</span></span>
<span><span class="co">## 6      d1           1        6                                .      PUNCT</span></span>
<span><span class="co">## 7      d2           1        1                        Mr._Smith nounphrase</span></span>
<span><span class="co">## 8      d2           1        2                            spent       VERB</span></span>
<span><span class="co">## 9      d2           1        3                        two_years nounphrase</span></span>
<span><span class="co">## 10     d2           1        4                               in        ADP</span></span>
<span><span class="co">## 11     d2           1        5                   North_Carolina nounphrase</span></span>
<span><span class="co">## 12     d2           1        6                                .      PUNCT</span></span></code></pre></div>
<p>If a user’s only goal is entity or noun phrase extraction, then two
functions make this easy without first parsing the entire text:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_extract_entity.html">spacy_extract_entity</a></span><span class="op">(</span><span class="va">txt</span><span class="op">)</span></span>
<span><span class="co">##   doc_id           text ent_type start_id length</span></span>
<span><span class="co">## 1     d2          Smith   PERSON        2      1</span></span>
<span><span class="co">## 2     d2      two years     DATE        4      2</span></span>
<span><span class="co">## 3     d2 North Carolina      GPE        7      2</span></span>
<span><span class="fu"><a href="../reference/spacy_extract_nounphrases.html">spacy_extract_nounphrases</a></span><span class="op">(</span><span class="va">txt</span><span class="op">)</span></span>
<span><span class="co">##   doc_id                             text  root_text start_id root_id length</span></span>
<span><span class="co">## 1     d1 fast natural language processing processing        5       8      4</span></span>
<span><span class="co">## 2     d2                        Mr. Smith      Smith        1       2      2</span></span>
<span><span class="co">## 3     d2                        two years      years        4       5      2</span></span>
<span><span class="co">## 4     d2                   North Carolina   Carolina        7       8      2</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="dependency-parsing">Dependency parsing<a class="anchor" aria-label="anchor" href="#dependency-parsing"></a>
</h3>
<p>Detailed parsing of syntactic dependencies is possible with the
<code>dependency = TRUE</code> option:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span>, dependency <span class="op">=</span> <span class="cn">TRUE</span>, lemma <span class="op">=</span> <span class="cn">FALSE</span>, pos <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">##    doc_id sentence_id token_id      token head_token_id  dep_rel   entity</span></span>
<span><span class="co">## 1      d1           1        1      spaCy             2    nsubj         </span></span>
<span><span class="co">## 2      d1           1        2         is             2     ROOT         </span></span>
<span><span class="co">## 3      d1           1        3      great             2    acomp         </span></span>
<span><span class="co">## 4      d1           1        4         at             2     prep         </span></span>
<span><span class="co">## 5      d1           1        5       fast             8     amod         </span></span>
<span><span class="co">## 6      d1           1        6    natural             7     amod         </span></span>
<span><span class="co">## 7      d1           1        7   language             8 compound         </span></span>
<span><span class="co">## 8      d1           1        8 processing             4     pobj         </span></span>
<span><span class="co">## 9      d1           1        9          .             2    punct         </span></span>
<span><span class="co">## 10     d2           1        1        Mr.             2 compound         </span></span>
<span><span class="co">## 11     d2           1        2      Smith             3    nsubj PERSON_B</span></span>
<span><span class="co">## 12     d2           1        3      spent             3     ROOT         </span></span>
<span><span class="co">## 13     d2           1        4        two             5   nummod   DATE_B</span></span>
<span><span class="co">## 14     d2           1        5      years             3     dobj   DATE_I</span></span>
<span><span class="co">## 15     d2           1        6         in             3     prep         </span></span>
<span><span class="co">## 16     d2           1        7      North             8 compound    GPE_B</span></span>
<span><span class="co">## 17     d2           1        8   Carolina             6     pobj    GPE_I</span></span>
<span><span class="co">## 18     d2           1        9          .             3    punct</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="extracting-additional-token-attributes">Extracting additional token attributes<a class="anchor" aria-label="anchor" href="#extracting-additional-token-attributes"></a>
</h3>
<p>It is also possible to extract additional <a href="https://spacy.io/api/token#attributes" class="external-link">attributes of spaCy
tokens</a> with the <code>additional_attributes</code> option. For
example, detecting numbers and email addresses:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="st">"I have six email addresses, including me@mymail.com."</span>, </span>
<span>            additional_attributes <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"like_num"</span>, <span class="st">"like_email"</span><span class="op">)</span>,</span>
<span>            lemma <span class="op">=</span> <span class="cn">FALSE</span>, pos <span class="op">=</span> <span class="cn">FALSE</span>, entity <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">##   doc_id sentence_id token_id         token like_num like_email</span></span>
<span><span class="co">## 1  text1           1        1             I    FALSE      FALSE</span></span>
<span><span class="co">## 2  text1           1        2          have    FALSE      FALSE</span></span>
<span><span class="co">## 3  text1           1        3           six     TRUE      FALSE</span></span>
<span><span class="co">## 4  text1           1        4         email    FALSE      FALSE</span></span>
<span><span class="co">## 5  text1           1        5     addresses    FALSE      FALSE</span></span>
<span><span class="co">## 6  text1           1        6             ,    FALSE      FALSE</span></span>
<span><span class="co">## 7  text1           1        7     including    FALSE      FALSE</span></span>
<span><span class="co">## 8  text1           1        8 me@mymail.com    FALSE       TRUE</span></span>
<span><span class="co">## 9  text1           1        9             .    FALSE      FALSE</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="using-other-language-models">Using other language models<a class="anchor" aria-label="anchor" href="#using-other-language-models"></a>
</h2>
<p>By default, <strong>spacyr</strong> loads an English language model.
You also can load spaCy’s other <a href="https://spacy.io/docs/usage/models" class="external-link">language models</a> or use one
of the <a href="https://spacy.io/docs/api/language-models#alpha-support" class="external-link">language
models with alpha support</a> by specifying the <code>model</code>
option when calling <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code>. We have
successfully tested following language models with spaCy version
2.0.18.</p>
<table class="table">
<thead><tr class="header">
<th align="left">Language</th>
<th align="left">ModelName</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">German</td>
<td align="left"><code>de</code></td>
</tr>
<tr class="even">
<td align="left">Spanish</td>
<td align="left"><code>es</code></td>
</tr>
<tr class="odd">
<td align="left">Portuguese</td>
<td align="left"><code>pt</code></td>
</tr>
<tr class="even">
<td align="left">French</td>
<td align="left"><code>fr</code></td>
</tr>
<tr class="odd">
<td align="left">Italian</td>
<td align="left"><code>it</code></td>
</tr>
<tr class="even">
<td align="left">Dutch</td>
<td align="left"><code>nl</code></td>
</tr>
</tbody>
</table>
<p>This is an example of parsing German texts.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## first finalize the old instance of spaCy if it's loaded</span></span>
<span><span class="fu"><a href="../reference/spacy_finalize.html">spacy_finalize</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/spacy_initialize.html">spacy_initialize</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"de_core_news_sm"</span><span class="op">)</span></span>
<span><span class="co">## successfully initialized (spaCy Version: 3.7.2, language model: de_core_news_sm)</span></span>
<span></span>
<span><span class="va">txt_german</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>R <span class="op">=</span> <span class="st">"R ist eine freie Programmiersprache für statistische Berechnungen und Grafiken. Sie wurde von Statistikern für Anwender mit statistischen Aufgaben entwickelt."</span>,</span>
<span>               python <span class="op">=</span> <span class="st">"Python ist eine universelle, üblicherweise interpretierte höhere Programmiersprache. Sie will einen gut lesbaren, knappen Programmierstil fördern."</span><span class="op">)</span></span>
<span><span class="va">results_german</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt_german</span>, dependency <span class="op">=</span> <span class="cn">FALSE</span>, lemma <span class="op">=</span> <span class="cn">FALSE</span>, tag <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">results_german</span></span>
<span><span class="co">##    doc_id sentence_id token_id              token   pos   tag entity</span></span>
<span><span class="co">## 1       R           1        1                  R     X    XY       </span></span>
<span><span class="co">## 2       R           1        2                ist   AUX VAFIN       </span></span>
<span><span class="co">## 3       R           1        3               eine   DET   ART       </span></span>
<span><span class="co">## 4       R           1        4              freie   ADJ  ADJA       </span></span>
<span><span class="co">## 5       R           1        5 Programmiersprache  NOUN    NN       </span></span>
<span><span class="co">## 6       R           1        6                für   ADP  APPR       </span></span>
<span><span class="co">## 7       R           1        7       statistische   ADJ  ADJA       </span></span>
<span><span class="co">## 8       R           1        8       Berechnungen  NOUN    NN       </span></span>
<span><span class="co">## 9       R           1        9                und CCONJ   KON       </span></span>
<span><span class="co">## 10      R           1       10           Grafiken  NOUN    NN       </span></span>
<span><span class="co">## 11      R           1       11                  . PUNCT    $.       </span></span>
<span><span class="co">## 12      R           2        1                Sie  PRON  PPER       </span></span>
<span><span class="co">## 13      R           2        2              wurde   AUX VAFIN       </span></span>
<span><span class="co">## 14      R           2        3                von   ADP  APPR       </span></span>
<span><span class="co">## 15      R           2        4       Statistikern  NOUN    NN       </span></span>
<span><span class="co">## 16      R           2        5                für   ADP  APPR       </span></span>
<span><span class="co">## 17      R           2        6           Anwender  NOUN    NN       </span></span>
<span><span class="co">## 18      R           2        7                mit   ADP  APPR       </span></span>
<span><span class="co">## 19      R           2        8      statistischen   ADJ  ADJA       </span></span>
<span><span class="co">## 20      R           2        9           Aufgaben  NOUN    NN       </span></span>
<span><span class="co">## 21      R           2       10         entwickelt  VERB  VVPP       </span></span>
<span><span class="co">## 22      R           2       11                  . PUNCT    $.       </span></span>
<span><span class="co">## 23 python           1        1             Python  NOUN    NN MISC_B</span></span>
<span><span class="co">## 24 python           1        2                ist   AUX VAFIN       </span></span>
<span><span class="co">## 25 python           1        3               eine   DET   ART       </span></span>
<span><span class="co">## 26 python           1        4        universelle   ADJ  ADJA       </span></span>
<span><span class="co">## 27 python           1        5                  , PUNCT    $,       </span></span>
<span><span class="co">## 28 python           1        6      üblicherweise   ADV   ADV       </span></span>
<span><span class="co">## 29 python           1        7     interpretierte   ADJ  ADJA       </span></span>
<span><span class="co">## 30 python           1        8             höhere   ADJ  ADJA       </span></span>
<span><span class="co">## 31 python           1        9 Programmiersprache  NOUN    NN       </span></span>
<span><span class="co">## 32 python           1       10                  . PUNCT    $.       </span></span>
<span><span class="co">## 33 python           2        1                Sie  PRON  PPER       </span></span>
<span><span class="co">## 34 python           2        2               will   AUX VMFIN       </span></span>
<span><span class="co">## 35 python           2        3              einen   DET   ART       </span></span>
<span><span class="co">## 36 python           2        4                gut   ADV  ADJD       </span></span>
<span><span class="co">## 37 python           2        5           lesbaren   ADJ  ADJA       </span></span>
<span><span class="co">## 38 python           2        6                  , PUNCT    $,       </span></span>
<span><span class="co">## 39 python           2        7            knappen   ADJ  ADJA       </span></span>
<span><span class="co">## 40 python           2        8    Programmierstil  NOUN    NN       </span></span>
<span><span class="co">## 41 python           2        9            fördern  VERB VVINF       </span></span>
<span><span class="co">## 42 python           2       10                  . PUNCT    $.</span></span>
<span><span class="fu"><a href="../reference/spacy_finalize.html">spacy_finalize</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>Note that the additional language models must first be installed in
spaCy. When spaCy has been installed through
<code><a href="../reference/spacy_install.html">spacy_install()</a></code>, installation of additional language models
is very simple. For example, the German language model can be installed
(<code>spacy_download_langmodel("de_core_news_sm")</code>). In other
environments, you can install the model by entering
<code>python -m spacy download de</code> in the console.</p>
</div>
<div class="section level2">
<h2 id="integrating-spacyr-with-other-text-analysis-packages">Integrating <strong>spacyr</strong> with other text analysis
packages<a class="anchor" aria-label="anchor" href="#integrating-spacyr-with-other-text-analysis-packages"></a>
</h2>
<div class="section level3">
<h3 id="with-quanteda">With <strong>quanteda</strong><a class="anchor" aria-label="anchor" href="#with-quanteda"></a>
</h3>
<p>The outputs and formats of <strong>spacyr</strong> are designed to
integrate directly with the <strong>quanteda</strong> package.</p>
<p>For instance, many of its functions operate directly on
<strong>spacyr</strong> objects, such as a parsed text.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://quanteda.io" class="external-link">quanteda</a></span>, warn.conflicts <span class="op">=</span> <span class="cn">FALSE</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/docnames.html" class="external-link">docnames</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">## [1] "d1" "d2"</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/ndoc.html" class="external-link">ndoc</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">## [1] 2</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/ntoken.html" class="external-link">ntoken</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">## d1 d2 </span></span>
<span><span class="co">##  9  9</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/ntoken.html" class="external-link">ntype</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">## d1 d2 </span></span>
<span><span class="co">##  9  9</span></span></code></pre></div>
<p>Conversion of tokens is easily performed, and the tokenizers in
<strong>spacyr</strong> tend to be smarter than the purely syntactic
pattern-based parsers used by <strong>quanteda</strong>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_initialize.html">spacy_initialize</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"en_core_web_sm"</span><span class="op">)</span></span>
<span><span class="co">## successfully initialized (spaCy Version: 3.7.2, language model: en_core_web_sm)</span></span>
<span><span class="va">parsedtxt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span>, pos <span class="op">=</span> <span class="cn">TRUE</span>, tag <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="va">parsedtxt</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 2 documents.</span></span>
<span><span class="co">## d1 :</span></span>
<span><span class="co">## [1] "spaCy"      "is"         "great"      "at"         "fast"      </span></span>
<span><span class="co">## [6] "natural"    "language"   "processing" "."         </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## d2 :</span></span>
<span><span class="co">## [1] "Mr."      "Smith"    "spent"    "two"      "years"    "in"       "North"   </span></span>
<span><span class="co">## [8] "Carolina" "."</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="va">parsedtxt</span>, include_pos <span class="op">=</span> <span class="st">"pos"</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 2 documents.</span></span>
<span><span class="co">## d1 :</span></span>
<span><span class="co">## [1] "spaCy/INTJ"      "is/AUX"          "great/ADJ"       "at/ADP"         </span></span>
<span><span class="co">## [5] "fast/ADJ"        "natural/ADJ"     "language/NOUN"   "processing/NOUN"</span></span>
<span><span class="co">## [9] "./PUNCT"        </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## d2 :</span></span>
<span><span class="co">## [1] "Mr./PROPN"      "Smith/PROPN"    "spent/VERB"     "two/NUM"       </span></span>
<span><span class="co">## [5] "years/NOUN"     "in/ADP"         "North/PROPN"    "Carolina/PROPN"</span></span>
<span><span class="co">## [9] "./PUNCT"</span></span>
<span><span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="va">parsedtxt</span>, include_pos <span class="op">=</span> <span class="st">"tag"</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 2 documents.</span></span>
<span><span class="co">## d1 :</span></span>
<span><span class="co">## [1] "spaCy/UH"      "is/VBZ"        "great/JJ"      "at/IN"        </span></span>
<span><span class="co">## [5] "fast/JJ"       "natural/JJ"    "language/NN"   "processing/NN"</span></span>
<span><span class="co">## [9] "./."          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## d2 :</span></span>
<span><span class="co">## [1] "Mr./NNP"      "Smith/NNP"    "spent/VBD"    "two/CD"       "years/NNS"   </span></span>
<span><span class="co">## [6] "in/IN"        "North/NNP"    "Carolina/NNP" "./."</span></span></code></pre></div>
<p>The latter is useful for say, selecting only nouns, using “glob”
pattern matching with <strong>quanteda</strong>’s
<code><a href="https://quanteda.io/reference/tokens_select.html" class="external-link">tokens_select()</a></code> function:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="st">"The cat in the hat ate green eggs and ham."</span>, pos <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span>include_pos <span class="op">=</span> <span class="st">"pos"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://quanteda.io/reference/tokens_select.html" class="external-link">tokens_select</a></span><span class="op">(</span>pattern <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"*/NOUN"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 1 document.</span></span>
<span><span class="co">## text1 :</span></span>
<span><span class="co">## [1] "cat/NOUN"  "hat/NOUN"  "eggs/NOUN"</span></span></code></pre></div>
<p>Direct conversion of just the spaCy-based tokens is also
possible:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_tokenize.html">spacy_tokenize</a></span><span class="op">(</span><span class="va">txt</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 2 documents.</span></span>
<span><span class="co">## d1 :</span></span>
<span><span class="co">## [1] "spaCy"      "is"         "great"      "at"         "fast"      </span></span>
<span><span class="co">## [6] "natural"    "language"   "processing" "."         </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## d2 :</span></span>
<span><span class="co">## [1] "Mr."      "Smith"    "spent"    "two"      "years"    "in"       "North"   </span></span>
<span><span class="co">## [8] "Carolina" "."</span></span></code></pre></div>
<p>including for sentences, for which spaCy’s recognition is very
smart:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">txt2</span> <span class="op">&lt;-</span> <span class="st">"A Ph.D. in Washington D.C.  Mr. Smith went to Washington."</span></span>
<span><span class="fu"><a href="../reference/spacy_tokenize.html">spacy_tokenize</a></span><span class="op">(</span><span class="va">txt2</span>, what <span class="op">=</span> <span class="st">"sentence"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 1 document.</span></span>
<span><span class="co">## text1 :</span></span>
<span><span class="co">## [1] "A Ph.D. in Washington D.C.  Mr. Smith went to Washington."</span></span></code></pre></div>
<p>This also works well with entity recognition, e.g.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="va">txt</span>, entity <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="../reference/entity_extract.html">entity_consolidate</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://quanteda.io/reference/as.tokens.html" class="external-link">as.tokens</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">## Tokens consisting of 1 document.</span></span>
<span><span class="co">## d1 :</span></span>
<span><span class="co">## [1] "spaCy"      "is"         "great"      "at"         "fast"      </span></span>
<span><span class="co">## [6] "natural"    "language"   "processing" "."</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="with-tidytext">With <strong>tidytext</strong><a class="anchor" aria-label="anchor" href="#with-tidytext"></a>
</h3>
<p>If you prefer a tidy approach to text analysis,
<strong>spacyr</strong> works nicely because it returns parsed texts and
(optionally) tokenized texts as data.frame-based objects.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"tidytext"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"tidytext"</span>, repos <span class="op">=</span> <span class="st">"https://cran.rstudio.com/"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/juliasilge/tidytext" class="external-link">"tidytext"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html" class="external-link">unnest_tokens</a></span><span class="op">(</span><span class="va">parsedtxt</span>, <span class="va">word</span>, <span class="va">token</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter-joins.html" class="external-link">anti_join</a></span><span class="op">(</span><span class="va">stop_words</span><span class="op">)</span></span>
<span><span class="co">## Joining with `by = join_by(word)`</span></span>
<span><span class="co">##   doc_id sentence_id token_id      lemma   pos tag   entity       word</span></span>
<span><span class="co">## 1     d1           1        1      spacy  INTJ  UH               spacy</span></span>
<span><span class="co">## 2     d1           1        5       fast   ADJ  JJ                fast</span></span>
<span><span class="co">## 3     d1           1        6    natural   ADJ  JJ             natural</span></span>
<span><span class="co">## 4     d1           1        7   language  NOUN  NN            language</span></span>
<span><span class="co">## 5     d1           1        8 processing  NOUN  NN          processing</span></span>
<span><span class="co">## 6     d2           1        2      Smith PROPN NNP PERSON_B      smith</span></span>
<span><span class="co">## 7     d2           1        3      spend  VERB VBD               spent</span></span>
<span><span class="co">## 8     d2           1        7      North PROPN NNP    GPE_B      north</span></span>
<span><span class="co">## 9     d2           1        8   Carolina PROPN NNP    GPE_I   carolina</span></span></code></pre></div>
<p>Part of speech filtering can then happen using
<strong>dplyr</strong>:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_parse.html">spacy_parse</a></span><span class="op">(</span><span class="st">"The cat in the hat ate green eggs and ham."</span>, pos <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/pkg/tidytext/man/unnest_tokens.html" class="external-link">unnest_tokens</a></span><span class="op">(</span><span class="va">word</span>, <span class="va">token</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>    <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">pos</span> <span class="op">==</span> <span class="st">"NOUN"</span><span class="op">)</span></span>
<span><span class="co">##   doc_id sentence_id token_id lemma  pos entity word</span></span>
<span><span class="co">## 1  text1           1        2   cat NOUN         cat</span></span>
<span><span class="co">## 2  text1           1        5   hat NOUN         hat</span></span>
<span><span class="co">## 3  text1           1        8   egg NOUN        eggs</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="adherence-to-the-tif-standard">Adherence to the “TIF” standard<a class="anchor" aria-label="anchor" href="#adherence-to-the-tif-standard"></a>
</h3>
<p><strong>spacyr</strong>’s output was designed to conform to the <a href="https://github.com/ropenscilabs/tif" class="external-link">Text Interchange Format</a>,
a cooperatively agreed standard structure for text package objects in R,
such as corpus and token objects. <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code> can
take a TIF corpus data.frame or character object as a valid input.
Moreover, the data.frames returned by <code><a href="../reference/spacy_parse.html">spacy_parse()</a></code> and
<code><a href="../reference/entity_extract.html">entity_consolidate()</a></code> conform to the TIF tokens standard for
data.frame tokens objects. This will make it easier to use with any text
analysis package for R that works with TIF standard objects.</p>
</div>
</div>
<div class="section level2">
<h2 id="finishing-a-session">Finishing a session<a class="anchor" aria-label="anchor" href="#finishing-a-session"></a>
</h2>
<p>When <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code> is executed, a background
process of spaCy is attached in python space. This can take up a
significant size of memory especially when a larger language model is
used (e.g. <a href="https://spacy.io/models/en#en_core_web_lg" class="external-link">en_core_web_lg</a>).
When you do not need the connection to spaCy any longer, you can remove
the spaCy object by calling the <code><a href="../reference/spacy_finalize.html">spacy_finalize()</a></code>
function.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spacy_finalize.html">spacy_finalize</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>By calling <code><a href="../reference/spacy_initialize.html">spacy_initialize()</a></code> again, you can reattach
the backend spaCy.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Kenneth Benoit, Akitaka Matsuo, European Research Council.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '6db886781d6c5d5b8b62b7b72b1d1b7c',
    indexName: 'spacyr',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
